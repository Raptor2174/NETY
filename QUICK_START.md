# üöÄ QUICK START - Cortex Textuel RNN

## TL;DR (Trop Long; Pas Lu)

```python
from nety.core.brain import Brain

brain = Brain()  # ‚úÖ Cortex cr√©√© automatiquement!
response = brain.think("Bonjour")  # ‚úÖ Utilise le cortex automatiquement!
print(response)
```

---

## 5 Minutes Pour Comprendre

### Qu'est-ce qui a chang√©?

**Ancien RNN:**
```
Simple LSTM (2 couches) ‚Üí Output
```

**Nouveau Cortex Textuel:**
```
Embedding
  ‚Üì
Attention multi-t√™te (4)
  ‚Üì
Bi-LSTM (3 couches)
  ‚Üì
√âtat PERSISTANT entre interactions
  ‚Üì
Modulation √©motionnelle
  ‚Üì
Output
```

### 3 Faits Cl√©s

1. **√âtat Persistant** üß†
   - Le r√©seau "se souvient" entre les messages
   - M√©moire √† court-terme via √©tat LSTM
   - M√©moire contextuelle via fen√™tre glissante

2. **Modulation √âmotionnelle** ‚ù§Ô∏è
   - √âmotions du limbic system modulent l'activation
   - R√©ponses plus empathiques
   - Adaptation au contexte

3. **Production Ready** ‚úÖ
   - ~2500 lignes de code new
   - Tests complets (5 suites)
   - Documentation complete

---

## Lancer les Tests (30 secondes)

```bash
python tests/test_textual_cortex.py
```

R√©sultat:
```
‚úÖ TEST 1: Mod√®le RNN Brut
‚úÖ TEST 2: Cortex Autonome
‚úÖ TEST 3: Modulation √âmotionnelle
‚úÖ TEST 4: Statistiques
‚úÖ TEST 5: Persistance d'√âtat
‚úÖ TOUS LES TESTS R√âUSSIS!
```

---

## Lancer la D√©mo (2 minutes)

```bash
# Mode automatis√© (4 messages)
python scripts/demo_rnn_cortex.py --mode demo

# Mode interactif (conversation libre)
python scripts/demo_rnn_cortex.py --mode interactive
```

---

## Utilisation Simple

```python
from nety.core.brain import Brain

# Initialiser
brain = Brain()

# Message 1
response = brain.think("Bonjour!")
print(response)

# Message 2 - Le cortex se souvient!
response = brain.think("Comment tu √ßa marche?")
print(response)

# Acc√©der aux stats
stats = brain.textual_cortex.get_neural_statistics()
print(f"Activation: {stats['current_activation']:.3f}")
print(f"Profondeur: {stats['context_depth']}")
```

---

## Utilisation Avanc√©e

```python
from nety.cortex_limbic.textual_cortex import TextualCortex
import torch

cortex = TextualCortex()

# Cr√©er un embedding (768 dimensions)
embedding = torch.randn(1, 5, 768)

# Traiter avec modulation √©motionnelle
emotional_context = {"emotions": {"joie": 0.8, "tristesse": 0.1}}

output, metadata = cortex.process_text_sequence(
    embedding,
    emotional_context=emotional_context,
    use_persistent_state=True  # Garder l'√©tat
)

print(f"Activation: {metadata['activation_level']:.3f}")
print(f"Output shape: {output.shape}")  # (1, 512)
```

---

## Fichiers Cl√©s

| Fichier | Usage |
|---------|-------|
| `nety/modules/text/modele_rnn.py` | Mod√®le RNN modernis√© |
| `nety/cortex_limbic/textual_cortex.py` | Cortex wrapper |
| `nety/core/brain.py` | Brain avec cortex int√©gr√© |
| `documentation/CORTEX_TEXTUEL_RNN.md` | Doc technique compl√®te |
| `CORTEX_TEXTUEL_INTEGRATION_GUIDE.md` | Guide d'int√©gration |
| `tests/test_textual_cortex.py` | Tests |
| `scripts/demo_rnn_cortex.py` | D√©mos |

---

## V√©rifier l'Int√©gration

```python
from nety.core.brain import Brain

brain = Brain()

# V√©rifier le cortex
assert hasattr(brain, 'textual_cortex'), "Cortex not found!"
print("‚úÖ Cortex est pr√©sent")

# V√©rifier les m√©thodes
assert hasattr(brain.textual_cortex, 'process_text_sequence')
assert hasattr(brain.textual_cortex, 'get_neural_statistics')
print("‚úÖ Toutes les m√©thodes sont disponibles")

# Test simple
response = brain.think("Bonjour")
print(f"‚úÖ Response: {response[:50]}...")

# Stats
stats = brain.textual_cortex.get_neural_statistics()
print(f"‚úÖ Activation: {stats['current_activation']:.3f}")
```

---

## Questions Fr√©quentes

**Q: Le cortex remplace-t-il le LLM?**
A: Non, c'est compl√©mentaire. Le cortex traite le texte, le LLM g√©n√®re la r√©ponse.

**Q: Est-ce que le code ancien continue √† marcher?**
A: Oui! R√©tro-compatibilit√© assur√©e.

**Q: Comment sauvegarder l'√©tat?**
A: `state = brain.textual_cortex.get_persistent_state()`

**Q: Comment restaurer l'√©tat?**
A: `brain.textual_cortex.load_persistent_state(state)`

**Q: √áa utilise GPU?**
A: Oui, automatiquement si disponible.

**Q: Combien de m√©moire √ßa prend?**
A: ~120 MB (mod√®le + √©tats)

---

## Documentation

Pour plus de d√©tails:

- üìñ **`documentation/CORTEX_TEXTUEL_RNN.md`** - Documentation technique (400+ lignes)
- üìñ **`CORTEX_TEXTUEL_INTEGRATION_GUIDE.md`** - Guide d'int√©gration (400+ lignes)
- üìñ **`RNN_MODERNIZATION_README.md`** - R√©sum√© rapide (150 lignes)
- üìä **`documentation/RNN_MODERNIZATION_SUMMARY.md`** - R√©sum√© avec visuals (350 lignes)

---

## Troubleshooting

**Erreur: "module 'nety.cortex_limbic' has no attribute 'TextualCortex'"**
‚Üí V√©rifier que `textual_cortex.py` existe
‚Üí V√©rifier que `__init__.py` l'exporte

**Erreur: "CUDA out of memory"**
‚Üí R√©duire `batch_size` ou `hidden_size`

**√âtat ne se sauvegarde pas**
‚Üí V√©rifier `use_persistent_state=True`

**Performance lente**
‚Üí Utiliser GPU (`device='cuda'`)
‚Üí R√©duire `num_layers` ou `seq_length`

---

## Architecture en 30 secondes

```
Input (Message)
    ‚Üì
Embedding (768 dim)
    ‚Üì
Attention (4 t√™tes) ‚Üê Focus sur parties cl√©s
    ‚Üì
LSTM Bi-directionnel (3 couches) ‚Üê Comprend des 2 c√¥t√©s
    ‚Üì
√âtat Persistant ‚Üê Se souvient
    ‚Üì
Modulation √âmotionnelle ‚Üê Adapt√© √©motionnellement
    ‚Üì
Output (512 dim)
```

---

## Performance

| M√©trique | Valeur |
|----------|--------|
| Param√®tres | 3.5M |
| Forward pass | 10-30ms |
| M√©moire | 120 MB |
| GPU Support | ‚úÖ Oui |

---

## Status

‚úÖ **OP√âRATIONNEL**  
‚úÖ **TEST√â**  
‚úÖ **DOCUMENT√â**  
‚úÖ **PRODUCTION-READY**  

---

## Commandes Rapides

```bash
# Tests
python tests/test_textual_cortex.py

# D√©mo automatis√©e
python scripts/demo_rnn_cortex.py --mode demo

# D√©mo interactive
python scripts/demo_rnn_cortex.py --mode interactive

# Utilisation simple
python -c "from nety.core.brain import Brain; b = Brain(); print(b.think('Bonjour'))"
```

---

**C'est tout!** üéâ

Pour plus de d√©tails, voir les fichiers de documentation.

*Cortex Textuel RNN v2.0 - Production Ready*
