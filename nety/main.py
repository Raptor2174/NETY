import time
from nety.core.brain import Brain
from nety.core.config import Config
from nety.core.system_init import initialize_system
from nety.core.nety_bridge import bridge  # ‚Üê NOUVEAU


class BoucleSettings:
    """Param√®tres de la boucle principale"""
    LOOP_DELAY = 0.05        # 50 ms entre chaque it√©ration
    IDLE_LOG_INTERVAL = 40   # log toutes les 40 boucles sans donn√©es


class NETYSystem:
    """Syst√®me principal NETY"""

    def __init__(self, model_type=None):
        self.config = Config()
        self.running = False
        self.idle_counter = 0
        self.brain = None
        self.model_type = model_type

    # ======================
    # D√âMARRAGE
    # ======================
    def start(self):
        print(
            f"Initialisation du syst√®me {self.config.APP_NAME} "
            f"version {self.config.VERSION}"
        )
        initialize_system()
        
        # Initialiser le Brain avec le mod√®le choisi
        self.brain = Brain(model_type=self.model_type)
        
        # Notifier le Bridge
        bridge.set_brain_initialized(True)
        bridge.set_system_running(True)
        
        self.running = True

    # ======================
    # BOUCLE PRINCIPALE
    # ======================
    def run(self):
        bridge._add_log("üîÑ Boucle principale NETY d√©marr√©e")

        while self.running:
            # PRIORIT√â 1: V√©rifier les messages du Dashboard via Bridge
            dashboard_message = bridge.get_from_dashboard(timeout=0.01)
            
            if dashboard_message:
                # Traiter le message du Dashboard
                self.handle_dashboard_message(dashboard_message)
                continue
            
            # PRIORIT√â 2: V√©rifier le fichier (pour compatibilit√©)
            input_data = self.check_for_input()

            if input_data is None:
                self.handle_idle()
                time.sleep(BoucleSettings.LOOP_DELAY)
                continue

            self.idle_counter = 0

            if not self.validate_input(input_data):
                time.sleep(BoucleSettings.LOOP_DELAY)
                continue

            processed_data = self.process_data(input_data)

            if not self.validate_output(processed_data):
                time.sleep(BoucleSettings.LOOP_DELAY)
                continue

            self.send_output(processed_data)

            time.sleep(BoucleSettings.LOOP_DELAY)

    # ======================
    # GESTION MESSAGES DASHBOARD
    # ======================
    def handle_dashboard_message(self, message: dict):
        """
        Traite un message provenant du Dashboard
        
        Args:
            message: Dict avec 'type', 'content', 'timestamp'
        """
        msg_type = message.get("type", "unknown")
        content = message.get("content", "")
        
        # Nettoyer tous les pr√©fixes possibles
        prefixes_to_remove = ["CHAT: ", "PROMPT: ", "CHAT:", "PROMPT:"]
        for prefix in prefixes_to_remove:
            if content.startswith(prefix):
                content = content[len(prefix):].strip()
                break  # Arr√™ter apr√®s le premier match
        
        bridge._add_log(f"üì® Message Dashboard re√ßu: {msg_type}")
        
        if msg_type == "prompt":
            # Traiter comme un prompt normal
            response = self.process_data(content)  # ‚úÖ content est nettoy√©
            # Renvoyer la r√©ponse au Dashboard
            bridge.send_from_nety(response, msg_type="response")
            
        elif msg_type == "command":
            # Ex√©cuter une commande syst√®me
            self.execute_command(content)
            
        elif msg_type == "chat":
            # Traiter comme une conversation
            response = self.process_data(content)  # ‚úÖ content est nettoy√©
            bridge.send_from_nety(response, msg_type="chat_response")

    def execute_command(self, command: str):
        """Ex√©cute une commande syst√®me"""
        bridge._add_log(f"‚öôÔ∏è Commande re√ßue: {command}")
        
        if command == "stop":
            self.stop()
        elif command == "status":
            stats = bridge.get_stats()
            bridge.send_from_nety(str(stats), msg_type="status")
        else:
            bridge.send_from_nety(f"Commande inconnue: {command}", msg_type="error")

    # ======================
    # GESTION IDLE
    # ======================
    def handle_idle(self):
        self.idle_counter += 1

        if self.idle_counter % BoucleSettings.IDLE_LOG_INTERVAL == 0:
            # Ne plus logger "En attente" pour ne pas polluer
            pass

    # ======================
    # ENTR√âES
    # ======================
    def check_for_input(self):
        """V√©rifie s'il y a des donn√©es d'entr√©e depuis fichier"""
        import os
        
        input_file = "tmp_to_nety.txt"
        
        try:
            if os.path.exists(input_file):
                with open(input_file, "r", encoding="utf-8") as f:
                    content = f.read().strip()
                
                if content:
                    with open(input_file, "w", encoding="utf-8") as f:
                        f.write("")
                    
                    bridge._add_log(f"üì• Donn√©es fichier re√ßues: {content[:50]}...")
                    return content
        
        except Exception as e:
            bridge._add_log(f"‚ö†Ô∏è Erreur lecture fichier: {e}")
        
        return None

    def validate_input(self, data) -> bool:
        return True

    # ======================
    # TRAITEMENT
    # ======================
    def process_data(self, data):
        """Traite les donn√©es avec le Brain"""
        if self.brain:
            try:
                result = self.brain.think(data)
                
                # Synchroniser l'√©tat des modules
                modules_status = self.brain.get_modules_status()
                bridge.update_modules_status(modules_status)
                
                return result
            except Exception as e:
                error_msg = f"Erreur lors du traitement: {type(e).__name__}: {str(e)}"
                bridge._add_log(f"‚ùå {error_msg}")
                import traceback
                traceback.print_exc()
                return f"‚ùå Erreur: {str(e)}"
        
        return f"processed_{data}"

    # ======================
    # SORTIES
    # ======================
    def validate_output(self, data) -> bool:
        return True

    def send_output(self, output_data):
        """Envoie la sortie (logs + potentiellement Dashboard)"""
        bridge._add_log(f"‚úÖ Sortie NETY: {output_data[:100]}...")

    # ======================
    # ARR√äT
    # ======================
    def stop(self):
        bridge._add_log(
            f"üõë Arr√™t du syst√®me {self.config.APP_NAME} "
            f"version {self.config.VERSION}"
        )
        bridge.set_system_running(False)
        self.running = False


# ======================
# POINT D'ENTR√âE
# ======================
def main():
    """Fonction principale - Point d'entr√©e pour console_scripts"""
    # Demander √† l'utilisateur quel mod√®le
    chosen_model = select_model_interactive()
    
    # Cr√©er le syst√®me avec le mod√®le choisi
    system = NETYSystem(model_type=chosen_model)
    system.start()
    
    try:
        system.run()
    except KeyboardInterrupt:
        system.stop()


if __name__ == "__main__":
    main()


def select_model_interactive():
    """Menu interactif de s√©lection de mod√®le"""

    print("\n" + "="*70)
    print("ü§ñ S√âLECTION DU MOD√àLE D'IA POUR NETY")
    print("="*70 + "\n")

    models = [
        {
            "name": "Mistral-7B (Local GPU - Puissant mais gourmand)",
            "type": "LOCAL",
            "key": "mistral",
            "cost": "Gratuit (utilise ton mat√©riel)",
            "internet": "Non requis",
            "speed": "Moyen (d√©pend GPU)",
            "quality": "Excellent",
            "ram": "8 GB + 4 GB VRAM (GPU)",
            "note": "‚ö†Ô∏è N√©cessite un GPU compatible CUDA"
        },
        {
            "name": "BLOOMZ-560M (Local CPU - L√©ger et rapide)",
            "type": "LOCAL",
            "key": "bloomz",
            "cost": "Gratuit (utilise ton mat√©riel)",
            "internet": "Non requis",
            "speed": "Rapide (CPU uniquement)",
            "quality": "Correct",
            "ram": "2 GB",
            "note": ""
        },
        {
            "name": "Groq Cloud - Llama 3.3 (Cloud ultra rapide)",
            "type": "CLOUD",
            "key": "groq",
            "cost": "Gratuit (14.4k req/jour)",
            "internet": "Requis",
            "speed": "‚ö°‚ö°‚ö° Ultra rapide (500 tok/sec)",
            "quality": "Excellent",
            "ram": "0 GB (cloud)",
            "note": ""
        },
        # ‚ú® NOUVEAU
        {
            "name": "RNN Local - TextualCortex (Exp√©rimental)",
            "type": "LOCAL",
            "key": "rnn",
            "cost": "Gratuit (utilise ton mat√©riel)",
            "internet": "Non requis",
            "speed": "Rapide (CPU/GPU)",
            "quality": "üß™ En apprentissage",
            "ram": "500 MB",
            "note": "üî¨ Mode test - Pour observer les progr√®s du RNN"
        },
    ]

    # Afficher les options
    for i, model in enumerate(models, 1):
        print(f"{i}. {model['name']}")
        print(f"   Type: {model['type']}")
        print(f"   üí∞ {model['cost']}")
        print(f"   üì∂ {model['internet']}")
        print(f"   ‚ö° {model['speed']}")
        print(f"   üß† {model['quality']}")
        print(f"   üíæ RAM: {model['ram']}")
        if model['note']:
            print(f"   {model['note']}")
        print()

    print("üí° Recommandations:")
    print("   ‚Ä¢ Pas de GPU ‚Üí BLOOMZ (option 2)")
    print("   ‚Ä¢ GPU disponible ‚Üí Mistral (option 1)")
    print("   ‚Ä¢ PC faible + internet ‚Üí Groq (option 3)")
    print("   ‚Ä¢ Tester le RNN local ‚Üí RNN (option 4) üß™")
    print()

    # S√©lection
    while True:
        try:
            choice = input("üëâ Choisis ton mod√®le (1, 2, 3 ou 4): ").strip()
            choice_int = int(choice)
            if 1 <= choice_int <= len(models):
                selected = models[choice_int - 1]
                print(f"\n‚úÖ Mod√®le s√©lectionn√©: {selected['name']}\n")
                return selected['key']
            else:
                print(f"‚ùå Choix invalide. Entre un nombre entre 1 et {len(models)}.")
        except ValueError:
            print("‚ùå Entr√©e invalide. Entre un nombre.")
        except KeyboardInterrupt:
            print("\n\nüëã Annulation...")
            exit(0)