"""
S√©lecteur de mod√®le interactif pour NETY
Mistral (local GPU) + BLOOMZ (local CPU) + Groq (cloud gratuit)
"""
import os
from typing import Literal

ModelChoice = Literal["mistral", "bloomz", "groq"]

class ModelSelector:
    """Gestionnaire de s√©lection de mod√®le"""
    
    def __init__(self):
        self.available_models = {
            "1": {
                "name": "mistral",
                "display": "Mistral-7B (Local GPU - Puissant mais gourmand)",
                "backend": "local",
                "requires_gpu": True,
                "ram_gb": 8,
                "vram_gb": 4,
                "cost": "üí∞ Gratuit (utilise ton mat√©riel)",
                "internet": "üì∂ Non requis",
                "speed": "‚ö° Moyen (d√©pend GPU)",
                "quality": "üß† Excellent",
            },
            "2": {
                "name": "bloomz",
                "display": "BLOOMZ-560M (Local CPU - L√©ger et rapide)",
                "backend": "local",
                "requires_gpu": False,
                "ram_gb": 2,
                "vram_gb": 0,
                "cost": "üí∞ Gratuit (utilise ton mat√©riel)",
                "internet": "üì∂ Non requis",
                "speed": "‚ö° Rapide (CPU uniquement)",
                "quality": "üß† Correct",
            },
            "3": {
                "name": "groq",
                "display": "Groq Cloud - Llama 3.2 (Cloud ultra rapide)",
                "backend": "cloud",
                "requires_gpu": False,
                "ram_gb": 0,
                "vram_gb": 0,
                "cost": "üí∞ Gratuit (14.4k req/jour)",
                "internet": "üì∂ Requis",
                "speed": "‚ö°‚ö°‚ö° Ultra rapide (500 tok/sec)",
                "quality": "üß† Excellent",
            }
        }
    
    def display_menu(self) -> None:
        """Affiche le menu de s√©lection avec d√©tails"""
        print("\n" + "=" * 70)
        print("ü§ñ S√âLECTION DU MOD√àLE D'IA POUR NETY")
        print("=" * 70)
        print()
        
        for key, model in self.available_models.items():
            print(f"{key}. {model['display']}")
            print(f"   Type: {model['backend'].upper()}")
            print(f"   {model['cost']}")
            print(f"   {model['internet']}")
            print(f"   {model['speed']}")
            print(f"   {model['quality']}")
            
            if model['ram_gb'] > 0:
                print(f"   üíæ RAM: {model['ram_gb']} GB", end="")
                if model['vram_gb'] > 0:
                    print(f" + {model['vram_gb']} GB VRAM (GPU)")
                else:
                    print()
            else:
                print(f"   üíæ RAM: 0 GB (cloud)")
            
            if model['requires_gpu']:
                print("   ‚ö†Ô∏è N√©cessite un GPU compatible CUDA")
            
            print()
        
        print("üí° Recommandations:")
        print("   ‚Ä¢ Pas de GPU ‚Üí BLOOMZ (option 2)")
        print("   ‚Ä¢ GPU disponible ‚Üí Mistral (option 1)")
        print("   ‚Ä¢ PC faible + internet ‚Üí Groq (option 3)")
        print()
    
    def get_user_choice(self) -> ModelChoice:
        """Demande √† l'utilisateur de choisir un mod√®le"""
        self.display_menu()
        
        while True:
            choice = input("üëâ Choisis ton mod√®le (1, 2 ou 3): ").strip()
            
            if choice in self.available_models:
                selected = self.available_models[choice]
                
                # V√©rifications sp√©cifiques
                if selected["name"] == "groq":
                    # V√©rifier la cl√© API Groq
                    api_key = os.getenv("GROQ_API_KEY", "")
                    if not api_key:
                        print("\n" + "=" * 70)
                        print("‚ùå ERREUR: Cl√© API Groq manquante!")
                        print("=" * 70)
                        print()
                        print("üìù Comment obtenir ta cl√© API GRATUITE:")
                        print()
                        print("  1. Va sur https://console.groq.com/")
                        print("  2. Clique sur 'Sign Up' (gratuit, pas de CB)")
                        print("  3. Une fois connect√©, va dans 'API Keys'")
                        print("  4. Clique 'Create API Key'")
                        print("  5. Copie la cl√© (commence par 'gsk_...')")
                        print()
                        print("  6. Ajoute-la dans ton fichier .env:")
                        print("     GROQ_API_KEY=gsk_votre_cl√©_ici")
                        print()
                        print("  OU d√©finis-la temporairement:")
                        print("     Windows: set GROQ_API_KEY=gsk_votre_cl√©")
                        print("     Linux:   export GROQ_API_KEY=gsk_votre_cl√©")
                        print()
                        print("üí° Limites gratuites Groq:")
                        print("   ‚Ä¢ 30 requ√™tes par minute")
                        print("   ‚Ä¢ 14 400 requ√™tes par jour")
                        print("   ‚Ä¢ Gratuit √† vie (pas de CB requise)")
                        print("   ‚Ä¢ Ultra rapide (500 tokens/sec)")
                        print()
                        
                        retry = input("As-tu ajout√© ta cl√© ? (o/n): ").strip().lower()
                        if retry == 'o':
                            # Recharger les variables d'environnement
                            from dotenv import load_dotenv
                            load_dotenv(override=True)
                            api_key = os.getenv("GROQ_API_KEY", "")
                            if api_key:
                                print("‚úÖ Cl√© API d√©tect√©e!")
                            else:
                                print("‚ùå Cl√© toujours manquante. Choisis une autre option.")
                                continue
                        else:
                            print("üëå Choisis une autre option pour l'instant.")
                            continue
                    
                    # V√©rifier la connexion internet
                    print("\nüåê V√©rification de la connexion internet...")
                    if not self._check_internet():
                        print("‚ùå Pas de connexion internet d√©tect√©e!")
                        print("üí° Groq n√©cessite internet. Choisis Mistral ou BLOOMZ.")
                        continue
                    
                    print("‚úÖ Connexion internet OK")
                    print(f"‚úÖ Groq API configur√©")
                    print()
                    print("üìä Informations Groq:")
                    print(f"   ‚Ä¢ Mod√®le: llama-3.2-3b-preview")
                    print(f"   ‚Ä¢ Vitesse: ~500 tokens/seconde")
                    print(f"   ‚Ä¢ Limite: 14 400 requ√™tes/jour")
                    print(f"   ‚Ä¢ Co√ªt: 0‚Ç¨ (gratuit)")
                    print()
                
                elif selected["name"] == "mistral":
                    # V√©rifier le GPU
                    import torch
                    if not torch.cuda.is_available():
                        print("\n‚ö†Ô∏è ATTENTION: Aucun GPU CUDA d√©tect√©!")
                        print("   Mistral-7B va tourner sur CPU (tr√®s lent)")
                        print()
                        confirm = input("Continuer quand m√™me ? (o/n): ").strip().lower()
                        if confirm != 'o':
                            print("üí° Choisis BLOOMZ (option 2) pour CPU")
                            continue
                
                print(f"\n‚úÖ Mod√®le s√©lectionn√©: {selected['display']}")
                print()
                return selected["name"]
            
            else:
                print("‚ùå Choix invalide. Entre 1, 2 ou 3.")
    
    def _check_internet(self) -> bool:
        """V√©rifie la connexion internet"""
        import requests
        try:
            response = requests.get("https://api.groq.com/openai/v1/models", timeout=3)
            return True
        except:
            return False
    
    def auto_select(self, prefer_local: bool = True) -> ModelChoice:
        """S√©lection automatique bas√©e sur les ressources"""
        import torch
        
        # Si pr√©f√®re cloud ET Groq disponible
        if not prefer_local:
            api_key = os.getenv("GROQ_API_KEY", "")
            if api_key and self._check_internet():
                print("ü§ñ Auto-s√©lection: Groq Cloud (API key d√©tect√©e)")
                return "groq"
        
        # Si GPU disponible ‚Üí Mistral
        if torch.cuda.is_available():
            print("ü§ñ Auto-s√©lection: Mistral-7B (GPU d√©tect√©)")
            return "mistral"
        
        # Sinon BLOOMZ (l√©ger pour CPU)
        print("ü§ñ Auto-s√©lection: BLOOMZ (CPU uniquement)")
        return "bloomz"


def select_model(interactive: bool = True) -> ModelChoice:
    """
    Fonction helper pour s√©lectionner un mod√®le
    
    Args:
        interactive: Si True, affiche un menu interactif
                    Si False, fait une s√©lection automatique
    
    Returns:
        Le nom du mod√®le choisi
    """
    selector = ModelSelector()
    
    if interactive:
        return selector.get_user_choice()
    else:
        return selector.auto_select()