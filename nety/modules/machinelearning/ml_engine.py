import torch
import torch.nn as nn

class MLEngine:
    def __init__(self, model=None):
        """
        Initialise le moteur ML
        
        Args:
            model: Mod√®le PyTorch (nn.Module) ou None pour un mod√®le par d√©faut
        """
        if model is None:
            # Cr√©er un mod√®le simple par d√©faut pour la V1
            self.model = self._create_default_model()
        else:
            self.model = model
        
        print("‚úì ML Engine initialis√©")

    def _create_default_model(self):
        """Cr√©e un mod√®le simple pour la V1 (sera remplac√© plus tard)"""
        # Pour l'instant, un mod√®le factice pour ne pas crasher
        class DummyModel(nn.Module):
            def __init__(self):
                super().__init__()
                self.fc = nn.Linear(10, 10)
            
            def forward(self, x):
                return self.fc(x)
        
        return DummyModel()

    # ==========================================
    # üéØ M√âTHODES APPEL√âES PAR BRAIN
    # ==========================================
    def transform_text(self, text: str) -> str:
        """
        Transforme/r√©√©crit un texte
        Pour V1 : impl√©mentation simple, sera am√©lior√©e avec ML
        """
        print(f"üîÑ ML Engine transforme : {text}")
        
        # Pour l'instant : transformation simple (V1)
        # Tu pourras ajouter le vrai ML plus tard
        transformed = text.upper()  # Exemple simple
        return f"[Transform√©] {transformed}"

    def generate_response(self, text: str) -> str:
        """
        G√©n√®re une r√©ponse conversationnelle
        Pour V1 : r√©ponses basiques, sera am√©lior√©e avec ML
        """
        print(f"üí¨ ML Engine g√©n√®re une r√©ponse pour : {text}")
        
        # Pour l'instant : r√©ponses pr√©d√©finies (V1)
        # Tu pourras ajouter un vrai mod√®le de langage plus tard
        responses = {
            "bonjour": "Bonjour ! Comment puis-je vous aider ?",
            "salut": "Salut ! Que puis-je faire pour toi ?",
            "comment √ßa va": "Je vais bien, merci ! Et toi ?"
        }
        
        text_lower = text.lower()
        for keyword, response in responses.items():
            if keyword in text_lower:
                return response
        
        return f"Je comprends que tu dis : '{text}'. Comment puis-je t'aider ?"

    # ==========================================
    # üß† M√âTHODES ML ORIGINALES
    # ==========================================
    def train(self, data, labels, epochs=10, learning_rate=0.01):
        """Entra√Æne le mod√®le"""
        optimizer = torch.optim.SGD(self.model.parameters(), lr=learning_rate)
        loss_fn = nn.CrossEntropyLoss()

        for epoch in range(epochs):
            self.model.train()
            optimizer.zero_grad()
            outputs = self.model(data)
            loss = loss_fn(outputs, labels)
            loss.backward()
            optimizer.step()
            print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}')

    def evaluate(self, data, labels):
        """√âvalue le mod√®le"""
        self.model.eval()
        with torch.no_grad():
            outputs = self.model(data)
            _, predicted = torch.max(outputs, 1)
            accuracy = (predicted == labels).sum().item() / labels.size(0)
        print(f'Accuracy: {accuracy * 100:.2f}%')
        return accuracy
    
    def predict(self, data):
        """Fait une pr√©diction brute"""
        self.model.eval()
        with torch.no_grad():
            outputs = self.model(data)
            _, predicted = torch.max(outputs, 1)
        return predicted