"""
DÃ©mo Autonome - Cortex Textuel RNN Standalone

DÃ©montre le cortex textuel sans dÃ©pendre du Brain ou d'autres modules externes.
"""

import sys
from pathlib import Path
import torch

# Ajouter le chemin du projet
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from nety.cortex_limbic.textual_cortex import TextualCortex
from nety.cortex_limbic.emotion_engine import EmotionEngine
from nety.modules.text.modele_rnn import ModeleRNN


def create_sample_embedding(text: str) -> torch.Tensor:
    """CrÃ©e un embedding simple pour un texte."""
    # Utiliser une graine dÃ©terministe basÃ©e sur le texte
    seed = sum(ord(c) for c in text)
    torch.manual_seed(seed % 10000)
    
    # CrÃ©er un embedding de 768 dimensions
    return torch.randn(1, 10, 768)


def demo_modele_rnn():
    """DÃ©mo du modÃ¨le RNN brut."""
    print("\n" + "="*70)
    print("ğŸ§  DÃ‰MO 1: ModÃ¨le RNN Brut avec Ã‰tat Persistant")
    print("="*70)
    
    # CrÃ©er le modÃ¨le
    model = ModeleRNN(
        input_size=768,
        hidden_size=256,
        output_size=512,
        num_layers=3,
        num_heads=4,
        dropout=0.3,
        bidirectional=True,
        use_attention=True
    )
    
    # Mettre en eval mode
    model.eval()
    
    print(f"\nâœ… ModÃ¨le RNN crÃ©Ã©: {sum(p.numel() for p in model.parameters()):,} paramÃ¨tres")
    print(f"   â”œâ”€ Device: {next(model.parameters()).device}")
    print(f"   â”œâ”€ Couches LSTM: 3 (bi-directionnelles)")
    print(f"   â”œâ”€ TÃªtes d'attention: 4")
    print(f"   â””â”€ Ã‰tat persistant: ACTIF\n")
    
    # Traiter 3 messages avec Ã©tat persistant
    messages = [
        "Bonjour, je suis votre assistant NETY",
        "Je suis capable d'apprendre de nos conversations",
        "Mon Ã©tat neuronal persiste entre les interactions"
    ]
    
    print("ğŸ“Š Traitement avec Ã‰tat Persistant:")
    print("-"*70)
    
    with torch.no_grad():
        for i, msg in enumerate(messages, 1):
            embedding = create_sample_embedding(msg)
            
            # Traiter avec Ã©tat persistant
            output = model(embedding, use_persistent_state=True)
            
            print(f"\n   Message {i}: {msg[:45]}...")
            print(f"   â”œâ”€ EntrÃ©e: {embedding.shape}")
            print(f"   â”œâ”€ Sortie: {output.shape}")
            print(f"   â”œâ”€ Norme: {torch.norm(output).item():.4f}")
            print(f"   â””â”€ Ã‰tat sauvegardÃ©: âœ“")
    
    # Afficher l'historique d'Ã©tat
    state_history = model.get_state_history()
    print(f"\nâœ¨ Ã‰tat cachÃ© persistant: {len(state_history)} enregistrements en mÃ©moire")
    
    return model


def demo_cortex_textuel():
    """DÃ©mo du cortex textuel complet."""
    print("\n" + "="*70)
    print("ğŸ§  DÃ‰MO 2: Cortex Textuel Autonome")
    print("="*70)
    
    # CrÃ©er l'emotion engine
    emotion_engine = EmotionEngine()
    
    # CrÃ©er le cortex
    cortex = TextualCortex(
        hidden_size=256,
        output_size=512,
        num_layers=3,
        num_heads=4,
        dropout=0.3,
        emotion_engine=emotion_engine
    )
    
    print(f"\nâœ… Cortex Textuel crÃ©Ã©")
    print(f"   â”œâ”€ RNN: 3 couches LSTM bi-directionnelles")
    print(f"   â”œâ”€ Attention: 4 tÃªtes")
    print(f"   â”œâ”€ Device: {cortex.device}")
    print(f"   â””â”€ Ã‰tat persistant: ACTIF\n")
    
    # Conversation multi-tours
    messages = [
        "Salut NETY, comment Ã§a va?",
        "Raconte-moi ce que tu as appris aujourd'hui",
        "Ton cerveau se souvient-il de nos conversations?"
    ]
    
    print("ğŸ’­ Conversation avec Modulation Ã‰motionnelle:")
    print("-"*70)
    
    with torch.no_grad():
        for i, msg in enumerate(messages, 1):
            embedding = create_sample_embedding(msg)
            
            # Traiter avec contexte Ã©motionnel
            emotional_context = {
                "current_emotion": "curiositÃ©" if i % 2 == 0 else "intÃ©rÃªt",
                "emotional_intensity": 0.7
            }
            
            output, metadata = cortex.process_text_sequence(
                embedding,
                emotional_context=emotional_context,
                use_persistent_state=True
            )
            
            print(f"\n   Message {i}: {msg[:40]}...")
            print(f"   â”œâ”€ Sortie: {output.shape}")
            print(f"   â”œâ”€ Activation: {metadata['activation_level']:.3f}")
            print(f"   â”œâ”€ Profondeur Ã‰tat: {metadata['state_depth']}")
            print(f"   â””â”€ Modulation Ã‰motionnelle: âœ“")
    
    # Afficher les statistiques
    stats = cortex.get_neural_statistics()
    print(f"\nğŸ“ˆ Statistiques Neurales:")
    print(f"   â”œâ”€ Total d'activations: {stats['total_activations']}")
    print(f"   â”œâ”€ Activation moyenne: {stats['average_activation']:.4f}")
    print(f"   â”œâ”€ Activation maximale: {stats['peak_activation']:.4f}")
    print(f"   â””â”€ Profondeur du contexte: {len(cortex.context_window)}")
    
    return cortex


def demo_modulation_emotionnelle():
    """DÃ©mo de la modulation Ã©motionnelle."""
    print("\n" + "="*70)
    print("â¤ï¸ DÃ‰MO 3: Modulation Ã‰motionnelle")
    print("="*70)
    
    emotion_engine = EmotionEngine()
    cortex = TextualCortex(
        hidden_size=256,
        output_size=512,
        num_layers=3,
        num_heads=4,
        emotion_engine=emotion_engine
    )
    
    print(f"\nâœ… Cortex avec Limbic System initialisÃ©\n")
    
    # Tester diffÃ©rents contextes Ã©motionnels
    contexts = [
        {"emotion": "joie", "intensity": 0.9},
        {"emotion": "tristesse", "intensity": 0.7},
        {"emotion": "colÃ¨re", "intensity": 0.8},
        {"emotion": "calme", "intensity": 0.5}
    ]
    
    print("ğŸ­ Impact des Ã‰motions sur l'Activation Neurales:")
    print("-"*70)
    
    with torch.no_grad():
        for ctx in contexts:
            embedding = create_sample_embedding("test")
            
            emotional_context = {
                "current_emotion": ctx["emotion"],
                "emotional_intensity": ctx["intensity"]
            }
            
            output, metadata = cortex.process_text_sequence(
                embedding,
                emotional_context=emotional_context,
                use_persistent_state=False
            )
            
            print(f"\n   Ã‰motion: {ctx['emotion'].upper()}")
            print(f"   â”œâ”€ IntensitÃ©: {ctx['intensity']:.1f}")
            print(f"   â”œâ”€ Activation Neurales: {metadata['activation_level']:.3f}")
            print(f"   â””â”€ Modulation Active: âœ“")


def main():
    """ExÃ©cute toutes les dÃ©mos."""
    print("\n" + "â•”" + "="*68 + "â•—")
    print("â•‘" + " "*18 + "ğŸ§  CORTEX TEXTUEL RNN - DÃ‰MO STANDALONE" + " "*11 + "â•‘")
    print("â•š" + "="*68 + "â•")
    
    try:
        # DÃ©mo 1: RNN brut
        model = demo_modele_rnn()
        
        # DÃ©mo 2: Cortex textuel
        cortex = demo_cortex_textuel()
        
        # DÃ©mo 3: Modulation Ã©motionnelle
        demo_modulation_emotionnelle()
        
        print("\n" + "="*70)
        print("âœ… TOUS LES DÃ‰MOS RÃ‰USSIS!")
        print("="*70)
        print("\nğŸ’¡ Le Cortex Textuel RNN est maintenant")
        print("   â”œâ”€ ComplÃ¨tement fonctionnel")
        print("   â”œâ”€ IntÃ©grÃ© aux systÃ¨mes Ã©motionnels")
        print("   â”œâ”€ Capable d'Ã©tat persistant")
        print("   â””â”€ PrÃªt pour l'intÃ©gration Brain complÃ¨te\n")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ Erreur lors de la dÃ©mo: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
