# download_mistral.py
from transformers import AutoModelForCausalLM, AutoTokenizer
from tqdm import tqdm
import os

print("üì• T√©l√©chargement de Mistral-7B...")
print("‚ö†Ô∏è Cela peut prendre 30-120 minutes selon ta connexion")
print()

model_name = "mistralai/Mistral-7B-Instruct-v0.2"

# T√©l√©charger le tokenizer (rapide)
print("1Ô∏è‚É£ T√©l√©chargement du tokenizer...")
tokenizer = AutoTokenizer.from_pretrained(model_name)
print("‚úÖ Tokenizer t√©l√©charg√©")

# T√©l√©charger le mod√®le (long)
print("\n2Ô∏è‚É£ T√©l√©chargement du mod√®le (14 GB)...")
print("üìç Destination:", os.path.expanduser("~/.cache/huggingface/hub/"))

# T√©l√©charger sans charger en m√©moire
from huggingface_hub import snapshot_download

snapshot_download(
    repo_id=model_name,
    cache_dir=f"./models",
    allow_patterns="*.safetensors",
    ignore_patterns="*.bin"
)

print("\n‚úÖ T√©l√©chargement termin√©!")