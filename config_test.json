{
  "hardware": {
    "gpu_name": "RTX 3060",
    "total_vram_gb": 12,
    "max_vram_usage_gb": 10.0,
    "enable_mixed_precision": true,
    "cpu_name": "Intel Core i5",
    "max_ram_usage_gb": 10.0,
    "num_workers": 4,
    "device": "cpu",
    "max_storage_gb": 30
  },
  "model": {
    "vocab_size": 50000,
    "pad_token_id": 0,
    "sos_token_id": 1,
    "eos_token_id": 2,
    "unk_token_id": 3,
    "embedding_dim": 512,
    "max_seq_length": 256,
    "cognitive_num_layers": 4,
    "cognitive_num_heads": 8,
    "cognitive_dim_feedforward": 2048,
    "cognitive_dropout": 0.1,
    "limbic_hidden_dim": 256,
    "limbic_num_emotions": 6,
    "limbic_dropout": 0.2,
    "rnn_encoder_hidden_dim": 512,
    "rnn_encoder_num_layers": 3,
    "rnn_encoder_bidirectional": true,
    "rnn_encoder_dropout": 0.3,
    "rnn_decoder_hidden_dim": 512,
    "rnn_decoder_num_layers": 3,
    "rnn_decoder_dropout": 0.3,
    "rnn_decoder_attention": true
  },
  "training": {
    "learning_rate": 0.0005,
    "min_learning_rate": 1e-06,
    "weight_decay": 0.01,
    "batch_size": 16,
    "gradient_accumulation_steps": 2,
    "max_grad_norm": 1.0,
    "num_epochs": 50,
    "warmup_steps": 1000,
    "eval_steps": 500,
    "save_steps": 1000,
    "early_stopping_patience": 5,
    "early_stopping_min_delta": 0.001,
    "optimizer_type": "adamw",
    "adam_beta1": 0.9,
    "adam_beta2": 0.999,
    "adam_epsilon": 1e-08,
    "scheduler_type": "cosine_with_warmup",
    "use_amp": true,
    "log_interval": 10,
    "checkpoint_dir": "checkpoints",
    "keep_last_n_checkpoints": 3
  },
  "memory": {
    "max_memories": 10000,
    "memory_embedding_dim": 512,
    "importance_threshold": 0.3,
    "importance_decay_rate": 0.95,
    "temporal_decay_enabled": true,
    "temporal_decay_halflife_days": 30.0,
    "consolidation_enabled": true,
    "consolidation_similarity_threshold": 0.85,
    "consolidation_interval_hours": 24.0,
    "retrieval_top_k": 5,
    "retrieval_similarity_threshold": 0.5,
    "access_boost": 1.2,
    "max_importance": 10.0,
    "memory_db_path": "data/memory/memories.db",
    "memory_index_type": "faiss"
  },
  "generation": {
    "decoding_strategy": "beam_search",
    "beam_size": 5,
    "beam_length_penalty": 0.6,
    "temperature": 0.8,
    "top_k": 50,
    "top_p": 0.9,
    "min_length": 5,
    "max_length": 128,
    "repetition_penalty": 1.2,
    "no_repeat_ngram_size": 3,
    "early_stopping": true,
    "num_return_sequences": 1,
    "do_sample": true,
    "max_inference_time_ms": 1000.0
  },
  "data": {
    "train_data_path": "data/training/conversations.json",
    "val_data_path": "data/validation/conversations.json",
    "test_data_path": "data/test/conversations.json",
    "tokenizer_type": "bpe",
    "tokenizer_path": "data/tokenizer/nety_tokenizer.json",
    "vocab_path": "data/tokenizer/vocab.txt",
    "train_split": 0.8,
    "val_split": 0.1,
    "test_split": 0.1,
    "lowercase": true,
    "remove_accents": false,
    "max_input_length": 256,
    "max_target_length": 128,
    "enable_augmentation": false,
    "augmentation_prob": 0.1
  },
  "version": "2.0-Maxx",
  "project_name": "NETY V2-Maxx",
  "description": "Modèle RNN local intelligent pour génération de conversations naturelles"
}