#!/usr/bin/env python3
"""
Script d'exemple d'utilisation de la base de connaissances NETY

Ce script d√©montre comment :
1. Initialiser les bases de donn√©es
2. Ajouter des connaissances
3. Rechercher des informations
4. Sauvegarder des conversations
5. Obtenir des statistiques
"""

from nety.knowledge_base import (
    init_databases,
    KnowledgeManager,
    SearchEngine
)


def main():
    print("=" * 70)
    print(" üß† NETY Knowledge Base - Exemple d'utilisation")
    print("=" * 70)
    print()
    
    # ===============================
    # 1. INITIALISATION
    # ===============================
    print("üìä √âtape 1 : Initialisation des bases de donn√©es")
    print("-" * 70)
    init_databases()
    print()
    
    # ===============================
    # 2. CR√âER LE GESTIONNAIRE
    # ===============================
    print("üìä √âtape 2 : Cr√©ation du gestionnaire de connaissances")
    print("-" * 70)
    km = KnowledgeManager()
    print("‚úÖ KnowledgeManager cr√©√©")
    print()
    
    # ===============================
    # 3. AJOUTER DES CONNAISSANCES
    # ===============================
    print("üìä √âtape 3 : Ajout de connaissances")
    print("-" * 70)
    
    # Connaissance sur les RNN
    rnn_id = km.add_knowledge(
        title="R√©seaux de Neurones R√©currents (RNN)",
        content="""Les r√©seaux de neurones r√©currents (RNN) sont un type d'architecture 
        de r√©seau de neurones con√ßu pour traiter des s√©quences de donn√©es. Contrairement 
        aux r√©seaux feedforward classiques, les RNN poss√®dent des connexions r√©currentes 
        qui leur permettent de maintenir une forme de m√©moire des entr√©es pr√©c√©dentes. 
        Cela les rend particuli√®rement adapt√©s pour le traitement du langage naturel, 
        la reconnaissance vocale et l'analyse de s√©ries temporelles.""",
        category="deep_learning",
        source="Documentation NETY",
        tags=["rnn", "neural_networks", "nlp", "sequences"],
        metadata={"difficulty": "intermediate", "language": "fr"}
    )
    print(f"‚úÖ Connaissance RNN ajout√©e (ID: {rnn_id})")
    
    # Connaissance sur les CNN
    cnn_id = km.add_knowledge(
        title="R√©seaux de Neurones Convolutionnels (CNN)",
        content="""Les r√©seaux de neurones convolutionnels (CNN) sont sp√©cialis√©s dans 
        le traitement de donn√©es ayant une structure en grille, comme les images. 
        Ils utilisent des couches de convolution pour d√©tecter automatiquement des 
        motifs et des caract√©ristiques visuelles. Les CNN sont largement utilis√©s 
        en vision par ordinateur pour des t√¢ches comme la classification d'images, 
        la d√©tection d'objets et la segmentation.""",
        category="deep_learning",
        source="Documentation NETY",
        tags=["cnn", "neural_networks", "computer_vision", "images"],
        metadata={"difficulty": "intermediate", "language": "fr"}
    )
    print(f"‚úÖ Connaissance CNN ajout√©e (ID: {cnn_id})")
    
    # Connaissance sur NETY
    nety_id = km.add_knowledge(
        title="NETY - IA Multimodale",
        content="""NETY est un projet d'intelligence artificielle multimodale capable 
        de traiter du texte (NLP), des images (CNN) et de l'audio (Speech-to-Text). 
        Le projet utilise PyTorch et TensorFlow comme frameworks principaux. 
        L'architecture est modulaire et extensible, permettant l'ajout facile 
        de nouvelles fonctionnalit√©s.""",
        category="project_info",
        source="README NETY",
        tags=["nety", "ai", "multimodal", "nlp", "vision", "audio"],
        metadata={"project": "NETY", "language": "fr"}
    )
    print(f"‚úÖ Connaissance NETY ajout√©e (ID: {nety_id})")
    print()
    
    # ===============================
    # 4. RECHERCHE DE CONNAISSANCES
    # ===============================
    print("üìä √âtape 4 : Recherche de connaissances")
    print("-" * 70)
    
    # Cr√©er le moteur de recherche
    search = SearchEngine()
    
    # Recherche 1: Recherche textuelle simple
    print("\nüîç Recherche 1 : 'r√©seaux de neurones'")
    results = search.search("r√©seaux de neurones", use_semantic=False)
    print(f"   Nombre de r√©sultats : {len(results)}")
    for i, result in enumerate(results, 1):
        print(f"   {i}. {result['title']} (Cat√©gorie: {result['category']})")
    
    # Recherche 2: Par cat√©gorie
    print("\nüîç Recherche 2 : Cat√©gorie 'deep_learning'")
    results = search.search(None, category="deep_learning")
    print(f"   Nombre de r√©sultats : {len(results)}")
    for i, result in enumerate(results, 1):
        print(f"   {i}. {result['title']}")
    
    # Recherche 3: Contexte pour RAG
    print("\nüîç Recherche 3 : Contexte pour 'qu'est-ce qu'un CNN?'")
    context = search.get_context_for_query("qu'est-ce qu'un CNN?", max_results=2)
    print(f"   Contexte r√©cup√©r√© ({len(context)} caract√®res)")
    print(f"   Aper√ßu: {context[:200]}...")
    print()
    
    # ===============================
    # 5. MISE √Ä JOUR D'UNE CONNAISSANCE
    # ===============================
    print("üìä √âtape 5 : Mise √† jour d'une connaissance")
    print("-" * 70)
    
    success = km.update_knowledge(
        nety_id,
        tags=["nety", "ai", "multimodal", "nlp", "vision", "audio", "python"],
        metadata={"project": "NETY", "language": "fr", "updated": True}
    )
    print(f"‚úÖ Mise √† jour {'r√©ussie' if success else '√©chou√©e'}")
    print()
    
    # ===============================
    # 6. CONVERSATIONS
    # ===============================
    print("üìä √âtape 6 : Sauvegarde de conversations")
    print("-" * 70)
    
    # Conversation 1
    conv1_id = km.save_conversation(
        user_input="Qu'est-ce qu'un RNN?",
        nety_response="Un RNN (R√©seau de Neurones R√©current) est un type de r√©seau "
                     "de neurones con√ßu pour traiter des s√©quences de donn√©es. "
                     "Il poss√®de une m√©moire des entr√©es pr√©c√©dentes.",
        session_id="demo_session_001",
        metadata={"language": "fr", "topic": "deep_learning"}
    )
    print(f"‚úÖ Conversation 1 sauvegard√©e (ID: {conv1_id})")
    
    # Conversation 2
    conv2_id = km.save_conversation(
        user_input="Et un CNN?",
        nety_response="Un CNN (R√©seau de Neurones Convolutionnel) est sp√©cialis√© "
                     "dans le traitement d'images. Il utilise des couches de "
                     "convolution pour d√©tecter des motifs visuels.",
        session_id="demo_session_001",
        metadata={"language": "fr", "topic": "deep_learning"}
    )
    print(f"‚úÖ Conversation 2 sauvegard√©e (ID: {conv2_id})")
    
    # R√©cup√©rer l'historique
    print("\nüìú Historique de la session 'demo_session_001':")
    history = km.get_conversation_history(session_id="demo_session_001")
    for i, conv in enumerate(history, 1):
        print(f"   {i}. User: {conv['user_input'][:50]}...")
        print(f"      NETY: {conv['nety_response'][:50]}...")
    print()
    
    # ===============================
    # 7. STATISTIQUES
    # ===============================
    print("üìä √âtape 7 : Statistiques de la base de connaissances")
    print("-" * 70)
    
    stats = km.get_stats()
    print(f"üìà Statistiques:")
    print(f"   - Nombre de connaissances : {stats['knowledge_count']}")
    print(f"   - Nombre de conversations : {stats['conversations_count']}")
    print(f"   - Cat√©gories :")
    for category, count in stats['categories'].items():
        print(f"      ‚Ä¢ {category}: {count} connaissance(s)")
    print(f"   - Chroma DB disponible : {'‚úÖ' if stats['chroma_available'] else '‚ùå'}")
    print(f"   - Redis disponible : {'‚úÖ' if stats['redis_available'] else '‚ùå'}")
    print()
    
    # ===============================
    # 8. EXEMPLE RAG (Retrieval-Augmented Generation)
    # ===============================
    print("üìä √âtape 8 : Exemple RAG - G√©n√©ration augment√©e par r√©cup√©ration")
    print("-" * 70)
    
    user_query = "Parle-moi des diff√©rents types de r√©seaux de neurones"
    print(f"‚ùì Question utilisateur : '{user_query}'")
    print()
    
    # R√©cup√©rer le contexte pertinent
    context = search.get_context_for_query(user_query, max_results=3)
    
    print("üìö Contexte r√©cup√©r√© de la base de connaissances:")
    print(f"   {len(context)} caract√®res de contexte pertinent")
    print()
    
    # Dans une vraie application, on utiliserait ce contexte avec un LLM
    print("üí° Utilisation typique:")
    print("   1. R√©cup√©rer le contexte pertinent (fait ‚úÖ)")
    print("   2. Combiner contexte + question utilisateur")
    print("   3. Envoyer au mod√®le de langage (Brain)")
    print("   4. G√©n√©rer une r√©ponse inform√©e")
    print()
    
    # ===============================
    # CONCLUSION
    # ===============================
    print("=" * 70)
    print("‚úÖ D√©monstration termin√©e avec succ√®s!")
    print()
    print("üí° La base de connaissances NETY est pr√™te √† √™tre utilis√©e.")
    print("   - Les donn√©es sont stock√©es dans: data/databases/")
    print("   - SQLite pour les donn√©es structur√©es")
    print("   - Chroma DB pour la recherche s√©mantique (si disponible)")
    print("   - Redis pour le cache (si disponible et activ√©)")
    print("=" * 70)


if __name__ == "__main__":
    main()
