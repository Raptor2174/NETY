"""
Exemple d'intÃ©gration de la base de connaissances avec le Brain de NETY
Ce fichier montre comment enrichir les rÃ©ponses de NETY avec des connaissances stockÃ©es
"""

from nety.knowledge_base import KnowledgeManager, SearchEngine, init_databases


class EnhancedBrain:
    """
    Version enrichie du Brain NETY avec accÃ¨s Ã  la base de connaissances
    """
    
    def __init__(self):
        # Initialiser la base de connaissances
        init_databases()
        
        self.km = KnowledgeManager()
        self.search = SearchEngine()
        
        # Initialiser avec quelques connaissances de base sur NETY
        self._initialize_base_knowledge()
    
    def _initialize_base_knowledge(self):
        """Initialise la base avec des connaissances sur NETY"""
        
        # VÃ©rifier si dÃ©jÃ  initialisÃ©
        stats = self.km.get_stats()
        if stats['knowledge_count'] > 0:
            print("ğŸ“š Base de connaissances dÃ©jÃ  initialisÃ©e")
            return
        
        print("ğŸ“š Initialisation de la base de connaissances...")
        
        # Ajouter des connaissances sur NETY
        self.km.add_knowledge(
            title="Qu'est-ce que NETY?",
            content="""NETY est un projet d'intelligence artificielle multimodale 
            conÃ§u pour le traitement du langage naturel (NLP), le traitement d'images (CNN) 
            et le traitement audio (Speech-to-Text). Le projet utilise PyTorch et TensorFlow 
            comme frameworks principaux et possÃ¨de une architecture modulaire et extensible.""",
            category="about_nety",
            tags=["nety", "ia", "multimodal"],
            metadata={"priority": "high", "language": "fr"}
        )
        
        self.km.add_knowledge(
            title="RNN - RÃ©seaux de Neurones RÃ©currents",
            content="""Les rÃ©seaux de neurones rÃ©currents (RNN) sont utilisÃ©s dans NETY 
            pour le traitement du langage naturel. Ils possÃ¨dent des connexions rÃ©currentes 
            qui leur permettent de maintenir une mÃ©moire des entrÃ©es prÃ©cÃ©dentes, 
            ce qui est essentiel pour comprendre le contexte dans les conversations.""",
            category="deep_learning",
            tags=["rnn", "nlp", "neural_networks"],
            metadata={"difficulty": "intermediate"}
        )
        
        self.km.add_knowledge(
            title="CNN - RÃ©seaux de Neurones Convolutionnels",
            content="""Les rÃ©seaux de neurones convolutionnels (CNN) sont utilisÃ©s dans NETY 
            pour le traitement d'images. Ils utilisent des couches de convolution pour dÃ©tecter 
            automatiquement des motifs et des caractÃ©ristiques visuelles dans les images.""",
            category="deep_learning",
            tags=["cnn", "computer_vision", "neural_networks"],
            metadata={"difficulty": "intermediate"}
        )
        
        print("âœ… Base de connaissances initialisÃ©e avec succÃ¨s")
    
    def think(self, user_input: str, session_id: str = None) -> str:
        """
        Processus de rÃ©flexion enrichi par la base de connaissances
        
        Args:
            user_input: Message de l'utilisateur
            session_id: ID de session pour le suivi
            
        Returns:
            RÃ©ponse de NETY enrichie par les connaissances
        """
        print(f"\nğŸ’­ NETY rÃ©flÃ©chit Ã : '{user_input}'")
        
        # 1. RÃ©cupÃ©rer le contexte pertinent de la base de connaissances
        context = self.search.get_context_for_query(user_input, max_results=2)
        
        if context:
            print(f"ğŸ“š Contexte rÃ©cupÃ©rÃ©: {len(context)} caractÃ¨res")
        else:
            print("ğŸ“š Aucun contexte spÃ©cifique trouvÃ©")
        
        # 2. GÃ©nÃ©rer la rÃ©ponse (simulation)
        # Dans la vraie implÃ©mentation, ceci serait envoyÃ© au modÃ¨le RNN/LLM
        response = self._generate_response(user_input, context)
        
        # 3. Sauvegarder la conversation
        self.km.save_conversation(
            user_input=user_input,
            nety_response=response,
            context=context[:500] if context else None,  # Limiter la taille
            session_id=session_id,
            metadata={"has_context": bool(context)}
        )
        
        return response
    
    def _generate_response(self, user_input: str, context: str) -> str:
        """
        Simule la gÃ©nÃ©ration de rÃ©ponse
        Dans la vraie implÃ©mentation, ceci utiliserait le modÃ¨le RNN/LLM
        """
        if not context:
            return "Je n'ai pas assez d'informations dans ma base de connaissances pour rÃ©pondre prÃ©cisÃ©ment Ã  cette question."
        
        # Simulation simplifiÃ©e
        return f"BasÃ© sur mes connaissances: {context[:200]}..."
    
    def add_knowledge_from_conversation(
        self,
        title: str,
        content: str,
        category: str = "learned"
    ):
        """
        Permet Ã  NETY d'apprendre de nouvelles connaissances
        """
        knowledge_id = self.km.add_knowledge(
            title=title,
            content=content,
            category=category,
            source="conversation",
            tags=["learned", "user_input"]
        )
        print(f"ğŸ“– Nouvelle connaissance apprise (ID: {knowledge_id})")
        return knowledge_id
    
    def get_knowledge_stats(self):
        """Retourne les statistiques de la base de connaissances"""
        return self.km.get_stats()


def demo_enhanced_brain():
    """DÃ©monstration du Brain enrichi"""
    
    print("=" * 70)
    print(" ğŸ§  NETY Enhanced Brain - DÃ©monstration")
    print("=" * 70)
    print()
    
    # CrÃ©er le Brain enrichi
    brain = EnhancedBrain()
    
    # Session de conversation
    session_id = "demo_session_001"
    
    # Conversation 1
    print("\n" + "-" * 70)
    user_input_1 = "Qu'est-ce que NETY?"
    response_1 = brain.think(user_input_1, session_id)
    print(f"\nğŸ‘¤ Utilisateur: {user_input_1}")
    print(f"ğŸ¤– NETY: {response_1}")
    
    # Conversation 2
    print("\n" + "-" * 70)
    user_input_2 = "Comment fonctionnent les RNN?"
    response_2 = brain.think(user_input_2, session_id)
    print(f"\nğŸ‘¤ Utilisateur: {user_input_2}")
    print(f"ğŸ¤– NETY: {response_2}")
    
    # Conversation 3 - Apprendre quelque chose de nouveau
    print("\n" + "-" * 70)
    print("\nğŸ“– NETY apprend une nouvelle connaissance...")
    brain.add_knowledge_from_conversation(
        title="LSTM - Long Short-Term Memory",
        content="""LSTM est une variante amÃ©liorÃ©e des RNN qui rÃ©sout le problÃ¨me 
        du gradient qui disparaÃ®t. Les LSTM utilisent des portes (gates) pour contrÃ´ler 
        le flux d'information et peuvent maintenir des dÃ©pendances Ã  long terme.""",
        category="deep_learning"
    )
    
    # Conversation 4 - Utiliser la nouvelle connaissance
    print("\n" + "-" * 70)
    user_input_3 = "Parle-moi des LSTM"
    response_3 = brain.think(user_input_3, session_id)
    print(f"\nğŸ‘¤ Utilisateur: {user_input_3}")
    print(f"ğŸ¤– NETY: {response_3}")
    
    # Afficher les statistiques
    print("\n" + "=" * 70)
    print(" ğŸ“Š Statistiques de la Base de Connaissances")
    print("=" * 70)
    stats = brain.get_knowledge_stats()
    print(f"Connaissances stockÃ©es: {stats['knowledge_count']}")
    print(f"Conversations sauvegardÃ©es: {stats['conversations_count']}")
    print(f"CatÃ©gories:")
    for cat, count in stats['categories'].items():
        print(f"  - {cat}: {count}")
    
    print("\n" + "=" * 70)
    print("âœ… DÃ©monstration terminÃ©e")
    print("=" * 70)


if __name__ == "__main__":
    demo_enhanced_brain()
